<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="amazon-emr">
   <title>s3:// Protocol</title>
   <body>
      <p>The <codeph>s3</codeph> protocol is used in a URL that specifies the location of an Amazon
         Simple Storage Service (Amazon S3) bucket. Amazon S3 provides secure, durable,
         highly-scalable object storage. For information about Amazon S3, see <xref
            href="https://aws.amazon.com/s3/" format="html" scope="external">Amazon S3</xref>. </p>
      <p>Before creating an external table with the s3 protocol you must configure Greenplum
         Database. See <xref href="#amazon-emr/s3_prereq" format="dita"/>.</p>
      <p>For the <codeph>s3</codeph> protocol, you specify a location for files and an optional
         configuration file in the <codeph>LOCATION</codeph> clause of the <codeph>CREATE EXTERNAL
            TABLE</codeph> command. This is the syntax.</p>
      <codeblock>'s3://<varname>S3_endpoint</varname>/<varname>bucket_name</varname>/[<varname>S3_prefix</varname>] [config=<varname>config_file_location</varname>]'</codeblock>
      <p>The <codeph>s3</codeph> protocol URL specifies the AWS S3 endpoint, S3 bucket name, and
         optional S3 file prefix. </p>
      <p>For information about the AWS S3 endpoints see <xref
            href="http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region" format="html"
            scope="external"
            >http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region</xref>. For
         information about S3 buckets and folders, see the Amazon S3 documentation <xref
            href="http://aws.amazon.com/documentation/s3/" format="html" scope="external"
            >http://aws.amazon.com/documentation/s3/</xref>.</p>
      <p>If you specify an <varname>S3_prefix</varname>, the <codeph>s3</codeph> protocol selects
         the files that have the specified S3 file prefix. The <codeph>s3</codeph> protocol does not
         use the slash character (<codeph>/</codeph>) as delimiter. For example, these files have
            <codeph>domain</codeph> as the <varname>S3_endpoint</varname>, and
            <codeph>test1</codeph> as the <varname>bucket_name</varname>.</p>
      <codeblock>s3://domain/test1/abc
s3://domain/test1/abc/
s3://domain/test1/abc/xx
s3://domain/test1/abcdef
s3://domain/test1/abcdefff</codeblock>
      <ul id="ul_yll_xjm_qv">
         <li>If the file location is <codeph>s3://domain/test1/abc</codeph>, the <codeph>s3</codeph>
            protocol selects all 5 files.</li>
         <li>If the file location is <codeph>s3://domain/test1/abc/</codeph>, the
               <codeph>s3</codeph> protocol selects the files
               <codeph>s3://domain/test1/abc/</codeph> and
            <codeph>s3://domain/test1/abc/xx</codeph>.</li>
         <li>If the file location is <codeph>s3://domain/test1/abcd</codeph>, the
               <codeph>s3</codeph> protocol selects the files
               <codeph>s3://domain/test1/abcdef</codeph> and
               <codeph>s3://domain/test1/abcdefff</codeph></li>
      </ul>
      <p>Wildcard characters are not supported in a <varname>S3_prefix</varname>. </p>
      <p>For information about the S3 prefix, see the Amazon S3 documentation <xref
            href="http://docs.aws.amazon.com/AmazonS3/latest/dev/ListingKeysHierarchy.html"
            format="html" scope="external">Listing Keys Hierarchically Using a Prefix and
            Delimiter</xref>.</p>
      <section>
         <title>About S3 Data Files</title>
         <p>All the files specified by the S3 file location
               (<varname>S3_endpoint</varname>/<varname>bucket_name</varname>/<varname>S3_prefix</varname>)
            are used as the source for the external table and must have the same format and each
            file must contain complete data rows. A data row cannot be split between files. Only the
               <codeph>TEXT</codeph> and <codeph>CSV</codeph> formats are supported. The files can
            be in gzip compressed format. The <codeph>s3</codeph> protocol recognizes the gzip
            format and uncompress the files. Only the gzip compression format is supported. </p>
         <p>The S3 file permissions must be <codeph>Open/Download</codeph> and <codeph>View</codeph>
            for the S3 user ID that is accessing the files.</p>
         <p>The <codeph>config</codeph> parameter specifies the location of the required
               <codeph>s3</codeph> protocol configuration file that contains AWS connection
            credentials and communication parameters. </p>
         <p>Each Greenplum Database segment instance must have access to the S3 location. Each
            segment can download one file at a time from S3 location using several threads. To take
            advantage of the parallel processing performed by the Greenplum Database segments, the
            files in the S3 location should be similar in size and the number of files should allow
            for multiple segments to download the data from the S3 location. For example, if the
            Greenplum Database system consists of 16 segments and there was sufficient network
            bandwidth, creating 16 files in the S3 location allows each segment to download a file
            from the S3 location. In contrast, if the location contained only 1 or 2 files, only 1
            or 2 segments download data.</p>
      </section>
      <section id="s3_config_param">
         <title>About the S3 Protocol config Parameter</title>
         <p>The optional <codeph>config</codeph> parameter specifies the location of the required
               <codeph>s3</codeph> protocol configuration file. The file contains AWS connection
            credentials and communication parameters. For information about the file, see <xref
               href="#amazon-emr/s3_config_file" format="dita"/>.</p>
         <p>The configuration file is required on all Greenplum Database segment hosts. This is
            default location is a location in the data directory of each Greenplum Database segment
            instance.<codeblock><varname>gpseg_data_dir</varname>/<varname>gpseg_prefix</varname><varname>N</varname>/s3/s3.conf</codeblock></p>
         <p>The <varname>gpseg_data_dir</varname> is the path to the Greenplum Database segment data
            directory, the <varname>gpseg_prefix</varname> is the segment prefix, and
               <varname>N</varname> is the segment ID. The segment data directory, prefix, and ID
            are set when you initialize a Greenplum Database system.</p>
         <p>If you have multiple segment instances on segment hosts, you can simplify the
            configuration by creating a single location on each segment host. Then you specify the
            absolute path to the location with the <codeph>config</codeph> parameter in the
               <codeph>s3</codeph> protocol <codeph>LOCATION</codeph> clause. This example specifies
            a location in the <codeph>gpadmin</codeph> home directory. </p>
         <codeblock>LOCATION ('s3://s3.amazonaws.com/test/my_data config=/home/gpadmin/s3.conf')</codeblock>
         <p>All segment instances on the hosts use the file
               <codeph>/home/gpadmin/s3/s3.conf</codeph>.</p>
      </section>
      <section id="s3_prereq"><title>s3 Protocol Prerequisites</title><p>Before you create a
            readable external table with the <codeph>s3</codeph> protocol, you must configure the
            Greenplum Database system.<ul id="ul_qlk_42s_55">
               <li>Configure the database to support the <codeph>s3</codeph> protocol.</li>
               <li>Create and install the <codeph>s3</codeph> protocol configuration file on all the
                  Greenplum Database segments.</li>
            </ul></p><p><b>To configure a database to support the <codeph>s3</codeph>
            protocol</b></p><ol id="ol_ptx_bfs_55">
            <li>Create a function to access the <codeph>s3</codeph> protocol library.<p>In each
                  Greenplum database that accesses an S3 bucket with the <codeph>s3</codeph>
                  protocol, create a function for the
               protocol:</p><codeblock>CREATE OR REPLACE FUNCTION read_from_s3() RETURNS integer AS
   '$libdir/gps3ext.so', 's3_import'
LANGUAGE C STABLE;</codeblock></li>
            <li> Declare the <codeph>s3</codeph> protocol and specify the function that is used to
               read from an S3
               bucket.<codeblock>CREATE PROTOCOL s3 (readfunc = read_from_s3);</codeblock></li>
         </ol><note>The protocol name <codeph>s3</codeph> must be the same as the protocol of the
            URL specified for the readable external table you create to access an S3 resource.
               <p>The function is called by every Greenplum Database segment instance. All segment
               hosts must have access to the S3 bucket.</p></note><b>To create and install the
               <codeph>s3</codeph> protocol configuration file</b><ol id="ol_c1r_nqt_55">
            <li>Create a configuration file with the S3 configuration information.</li>
            <li>Install the file in the same location for all Greenplum Database segments on all
                  hosts.<p>The default location is
                        <codeph><varname>gpseg_data_dir</varname>/<varname>gpseg_prefix</varname><varname>N</varname>/s3/s3.conf</codeph>.
                  If you can install the file in a different location, you must specify the location
                  with the <codeph>config</codeph> parameter in the <codeph>s3</codeph> protocol
                  URL. See <xref href="#amazon-emr/s3_config_param" format="dita"/>.</p></li>
         </ol></section>
      <section id="s3_config_file"><title>s3 Protocol Configuration File</title><p>When using the
               <codeph>s3</codeph> protocol, the <codeph>s3</codeph> protocol configuration file is
            required on all Greenplum Database segments. The default location is
            <codeblock><varname>gpseg_data_dir</varname>/<varname>gpseg-prefix</varname><varname>N</varname>/s3/s3.conf</codeblock></p><p>The
               <varname>gpseg_data_dir</varname> is the path to the Greenplum Database segment data
            directory, the <varname>gpseg-prefix</varname> is the segment prefix, and
               <varname>N</varname> is the segment ID. The segment data directory, prefix, and ID
            are set when you initialize a Greenplum Database system.</p><p>If you have multiple
            segment instances on segment hosts, you can simplify the configuration by creating a
            single location on each segment host. Then you specify the absolute path to the location
            with the <codeph>config</codeph> parameter in the <codeph>s3</codeph> protocol
               <codeph>LOCATION</codeph> clause. This example specifies a location in the
               <codeph>gpadmin</codeph> home directory.
            </p><codeblock>config=/home/gpadmin/s3/s3.conf</codeblock><p>All segment instances on
            the hosts use the file <codeph>/home/gpadmin/s3/s3.conf</codeph>.</p><p>The
               <codeph>s3</codeph> protocol configuration file is a text file that consists of a
               <codeph>[default]</codeph> section and parameters This is an example configuration
            file.<codeblock>[default]
secret = "secret"
accessid = "user access id"
connections = 3
chunksize = 67108864</codeblock></p><p>You
            can use the Greenplum Database <codeph>gpcheckcloud</codeph> utility to test the S3
            configuration file. See <xref href="#amazon-emr/s3chkcfg_utility" format="dita"/>.</p><sectiondiv>
            <p><b>s3 Configuration File Parameters</b></p>
            <parml>
               <plentry>
                  <pt>accessid</pt>
                  <pd>Required. AWS S3 ID to access the S3 bucket.</pd>
               </plentry>
               <plentry>
                  <pt>secret</pt>
                  <pd>Required. AWS S3 passcode for the S3 ID to access the S3 bucket.</pd>
               </plentry>
               <plentry>
                  <pt>chunksize</pt>
                  <pd>The buffer size for each segment thread. The default is 64 MB. The minimum is
                     2MB and the maximum is128MB.</pd>
               </plentry>
               <plentry>
                  <pt>threadnum</pt>
                  <pd>The maximum number of concurrent connections a segment can create when
                     downloading data from the S3 bucket. The default is 4. The minimum is 1 and the
                     maximum is 8.</pd>
               </plentry>
               <plentry>
                  <pt>encryption</pt>
                  <pd>Use connections that are secured with Secure Sockets Layer (SSL). Default
                     value is <codeph>true</codeph>. The values <codeph>true</codeph>,
                        <codeph>t</codeph>, <codeph>on</codeph>, <codeph>yes</codeph>, and
                        <codeph>y</codeph> (case insensitive) are treated as <codeph>true</codeph>.
                     Any other value is treated as <codeph>false</codeph>.</pd>
               </plentry>
               <plentry>
                  <pt>low_speed_limit</pt>
                  <pd>The download speed lower limit, in bytes per second. The default speed is
                     10240 (10K). If the download speed is slower than the limit for longer than the
                     time specified by <codeph>low_speed_time</codeph>, the download connection is
                     aborted and retried. After 3 retries, the <codeph>s3</codeph> protocol returns
                     an error. A value of 0 specifies no lower limit.</pd>
               </plentry>
               <plentry>
                  <pt>low_speed_time</pt>
                  <pd>When the connection speed is less than <codeph>low_speed_limit</codeph>, the
                     amount of time, in minutes, to wait before aborting a download from an S3
                     bucket. The default is 1 minute. A value of 0 specifies no time limit.</pd>
               </plentry>
            </parml>
            <note>You must ensure that there is sufficient memory on the Greenplum Database segment
               hosts when the <codeph>s3</codeph> protocol to accesses the files. Greenplum Database
               allocates <codeph>connections * chunksize</codeph> memory on each segment host when
               accessing S3 files.</note>
         </sectiondiv></section>
      <section>
         <title>s3 Protocol Limitations</title>
         <p>These are <codeph>s3</codeph> protocol limitations: <ul id="ul_xt5_4cz_55">
               <li>Only the S3 path-style URL is
                  supported.<codeblock>s3://<varname>S3_endpoint</varname>/<varname>bucketname</varname>/[<varname>S3_prefix</varname>]</codeblock></li>
            </ul><ul id="ul_qqg_qcz_55">
               <li>Only the S3 endpoint is supported. The protocol does not support virtual hosting
                  of S3 buckets (binding a domain name to an S3 bucket).</li>
               <li>AWS signature version 2 and version 4 signing process are supported. <p>For
                     information about the S3 endpoints supported by each signing process, see <xref
                        href="http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region"
                        format="html" scope="external"
                        >http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region</xref>.</p></li>
               <li>S3 encryption is not supported. The S3 file property <uicontrol>Server Side
                     Encryption</uicontrol> must be <codeph>None</codeph>.</li>
            </ul></p>
      </section>
      <section id="s3chkcfg_utility"><title>About the gpcheckcloud Utility</title><p>The Greenplum
            Database utility <codeph>gpcheckcloud</codeph> helps users create an <codeph>s3</codeph>
            protocol configuration file and test a configuration file. You can specify options to
            test the ability to access an S3 bucket with a configuration file, and optionally
            download data from files in the bucket.</p><p>If you run the utility without any
            options, it sends a template configuration file to <codeph>STDOUT</codeph>. You can
            capture the output and create an <codeph>s3</codeph> configuration file to connect to
            Amazon S3. </p><p>The utility is installed in the Greenplum Database
               <codeph>$GPHOME/bin</codeph> directory.</p><b>Syntax</b>
         <codeblock>gpcheckcloud {<b>-c</b> | <b>-d</b>} "<b>s3://</b><varname>S3_endpoint</varname>/<varname>bucketname</varname>/[<varname>S3_prefix</varname>]] config==<varname>path_to_config_file</varname>"

gpcheckcloud <b>-t</b>

gpcheckcloud <b>-h</b></codeblock>
         <b>Options</b>
         <parml>
            <plentry>
               <pt>-c</pt>
               <pd>Connect to the specified S3 location with the configuration specified in the
                     <codeph>s3</codeph> protocol URL and return information about the files in the
                  S3 location.</pd>
               <pd>If the connection fails, the utility displays information about failures such as
                  invalid credentials, prefix, or server address (DNS error), or server not
                  available.</pd>
            </plentry>
            <plentry>
               <pt>-d</pt>
               <pd>Download data from the specified S3 location with the configuration specified in
                  the <codeph>s3</codeph> protocol URL and send the output to
                     <codeph>STDOUT</codeph>.</pd>
               <pd>If files are gzip compressed, the uncompressed data is sent to
                     <codeph>STDOUT</codeph>.</pd>
            </plentry>
            <plentry>
               <pt>-t</pt>
               <pd>Sends a template configuration file to <codeph>STDOUT</codeph>. You can capture
                  the output and create an <codeph>s3</codeph> configuration file to connect to
                  Amazon S3. </pd>
            </plentry>
            <plentry>
               <pt>-h</pt>
               <pd>Display <codeph>gpcheckcloud</codeph> help.</pd>
            </plentry>
         </parml><p><b>Examples</b>
         </p><p>This example runs the utility without options to create a template
               <codeph>s3</codeph> configuration file <codeph>mytest_s3.config</codeph> in the
            current directory.<codeblock>gpcheckcloud -t > ./mytest_s3.config</codeblock></p><p>This
            example attempts to connect to an S3 bucket location with the <codeph>s3</codeph>
            configuration file
            <codeph>s3.mytestconf</codeph>.<codeblock>gpcheckcloud -c "s3://domain/test1/abc config=s3.mytestconf"</codeblock></p><p>Download
            all files from the S3 bucket location and send the output to <codeph>STDOUT</codeph>.
            <codeblock>gpcheckcloud -d "s3://domain/test1/abc config=s3.mytestconf"</codeblock></p></section>
   </body>
</topic>